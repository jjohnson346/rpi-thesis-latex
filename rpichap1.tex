%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                            CHAPTER ONE  - Introduction and Overview                        %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\chapter{Introduction and Overview}

\section{Background}
Question Answer (QA) \cite{radev2000ranking} is a prominent and growing sub-field of natural language processing, and of the larger
field of AI \cite{Russell:2003:AIM:773294}.  QA systems \cite{radev2000ranking} consist of agents that provide responses (correct ones, hopefully) to questions posed in natural language that call upon the agent to retrieve and reason upon vast stores of information.  QA systems are typically based on one of two approaches: an
information-retrieval \cite{manning2008introduction} approach or a knowledge-based \cite{brachman2004knowledge} approach.  Some of the most successful systems
as of late, however, utilize a blend of these two approaches, such as IBM's Watson.  A knowledge-base \cite{brachman2004knowledge} 
approach offers the advantages of allowing automated reasoning, and thus, justifications for answers.
But the knowledge bases involved have been manually generated by domain experts and knowledge
engineers --- a time-consuming, labor intensive endeavor.  An information-retrieval approach \cite{manning2008introduction}, where
candidate answers are screened from passages retrieved from documents retrieved from a core
information-retrieval (IR) system, are designed without the need to manually curate a knowledge
base, but typically offer no justification of answers.  In fact, these systems have no understanding
of the reasons for the answers they put forth, but instead typically provide answers based on statistical approaches that are utilized in black-box fashion, giving the user no insight into the rationale for 
responses.



\section{Goals}

The work proposed here seeks to advance the state of the art of QA by exploring 
this area within the context of developing an agent designed to correctly answer multiple-choice 
questions covering the domain of fraud detection.  As iterations of this agent are developed and presented
within this document, there will be an eye toward providing justification of answers, and as such, 
providing the user insight into the rationale for the response of the agent. A key element of this approach is the use of multiple-choice questions as an information
resource for generating assertions in the knowledge-base.  Such questions are potentially highly useful.  They are inherently semistructured and, as will be discussed, typically hold multiple pieces of information
in their stems, correct choices, and also, incorrect choices.

In short, then, the goal of this thesis is threefold:  First, introduce the use of psychometric AI \cite{bringsjord_schimanski_2004, psychoai.ijcai03} for 
researching methods in QA, where psychometric AI, here, is the  
development and validation of intelligent systems by applying their algorithms to taking multiple
choice tests.  Second, explore techniques by which the agent can answer questions while providing
reasoning for its answers, and specifically, using proof-based techniques.  Third, lay a foundation
for the rigorous science of fraud detection.  Finally, after having explored the various techniques 
presented in this thesis, make recommendations about future research in the field of QA.
In particular, we consider ways in which semantic approaches can be utilized in conjunction with 
the techniques presented here for developing knowledge-bases to advance the art of QA in the 
semantic direction.

\section{The Intelligent Agent Defined, For This Project}
In an effort to further detail the goals listed above, the definition of intelligent agent is made 
more explicit, here, as one capable not only of making intelligent decisions, but also of 
providing a justification for those decisions.  This is to be contrasted with agents of other 
AI \cite{Russell:2003:AIM:773294} systems, where decisions are provided without any justifications.  This type of agent, which
is the goal for this project, will be termed a ``reasoning agent".  It should also be mentioned the 
reasoning agent provides justifications in situations where there is uncertainty of outcome (which is 
typically the case for the domain in this project).

%# JOE: It's important to think about /how/ the agent will show its
%# reasoning.  The IBM folks, wrt to Watson, claimed that Watson did
%# show its reasoning.  But that's a very, very big stretch.  I think
%# the idea should be that the reasoning must be naturally sequential,
%# which means argument- or proof-based.  What if you coined a label
%# for the type of agent that is your focus?  Career-wise, I think that
%# would make a lot of sense.  //S
%
%# SELMER: understood.  I will keep this in mind as the dissertation 
%# research moves forward.

\section{An Overview of the Approach}

This section discusses the overall approach to developing the reasoning agent, as defined above.
The overarching idea is to develop successively more sophisticated agents --- starting with a naive
agent that uses only shallow techniques that largely leverages question features with patterns 
among questions of certain types discovered from exploring a training set.  In version 2, we elevate the 
level of sophistication of the agent, but still limit it  to shallow techniques, by basing  answers on 
information-retrieval-based techniques that incorporate sophisticated query-generation and 
document-collection-development techniques.  In version 3, we explore semantic approaches by attempting
to leverage training-set questions to answer test-set questions.  And finally, in version 4, we consider
a sophisticated agent that uses deep, semantic techniques to answer questions.

\subsection{Generation of KB assertions from Text Corpora and MCQs}

In version 3, where as mentioned, the agent utilizes a knowledge-base to answer questions,
we'll look at the generation of assertions from both the text corpus (the CFE Manual, discussed below),
and from other multiple-choice questions that overlap in the problem domain.  By overlap, we mean
that the question stem and correct answer of one question serve as the basis for assertions from which inferences can be made about the answer to a second, separate question.  Unfortunately, as we'll discuss later, the sparsity of the training set and test set were such that no such overlap could be found, so
engineered test-battery questions were created to demonstrate this approach.

\subsection{Reasoning with Uncertainty}

In order to cover the nondeterminism inherent when extracting information
using NLP techniques, the agent will incorporate uncertainty into its decisions.  As we'll see
in versions 1 and 2, the agent quantifies uncertainty by analysis of its various algorithms on the 
training set, and then utilizes this information to optimize its accuracy on the test set.

\subsection{Verification of the Agent via Test-Taking}

The method proposed in this work includes verification of these algorithms by assessing performance on multiple-choice questions.  In this project, the domain of fraud detection will be used, for which there is
a well-developed industry of testing subjects on knowledge in this domain.  The principal organization
responsible for this and its examination process are described below.

\subsubsection{The ACFE and the CFE Exam}


The ACFE (\url{http://www.acfe.com}) describes itself on its website as ``the world's largest anti-fraud organization and premier provider of anti-fraud training and education.''  Generally speaking, in order to become a readily employable expert in the field of fraud detection, certification by this organization is required.  (Among notable certified members of the ACFE is Harry Markopolos, the American forensic accountant who achieved fame by being the first to have uncovered the ponzi scheme perpetrated by Bernard Madoff and desperately tried to warn government securities officials years before the scam collapsed in the midst of the 2008 financial crisis \cite{markopolos2010}.)  The ACFE has well-defined requirements for becoming certified, based on a point system that considers a combination of professional experience and academic credentials.  However, the CFE exam is the credentialing centerpiece for the ACFE, and the details of this exam are described briefly below.

The CFE Exam is a computer-based exam.  The mechanics for preparing for and taking the exam begins with downloading a software package from the \href{http://www.acfe.com/CFE-Exam-Prep-Course-List.aspx}{prep course page of the ACFE website}.  This package includes the exam software, the Fraud Examiners Manual (on which the test is based), and a self-study application consisting of a battery of sample test questions, a complete practice exam, and tools for monitoring progress.  

The CFE exam consists of 4 sections, listed below:

\begin{itemize}
\item Financial Transactions and Fraud Schemes 
\item Law 
\item Investigation
\item Fraud Prevention and Deterrence.  
\end{itemize}

Each section consists of 125 multiple-choice and true-false questions.  The candidate is limited to 75 seconds to complete each question and a maximum total allocated time of 2.6 hours to complete each section.  Each CFE Exam section is taken separately.  The timing for each section is subject to the candidateâ€™s discretion.  However, all four sections of the exam must be completed and submitted to the ACFE for grading within a 30-day period.

\subsubsection{CFE manual}

The Fraud Examiners Manual (known by the CFE Agent as the `CFE Manual') is the text corpus on which all of the questions of the CFE Exam are based.  Each question includes a section heading that loosely maps to an individual section within the manual.  However, these sections are rough-grained; that is, relatively large (often 20--100 pages).  








