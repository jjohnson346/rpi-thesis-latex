%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                            ABSTRACT                             %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 
\specialhead{ABSTRACT}
 
This thesis explores various approaches for developing an intelligent agent in a
particular domain: fraud detection.  The 
framework by which we measure our agent is \textit{psychometric artificial intelligence}, or, 
more commonly, psychometric AI.  As we'll explore further, psychometric AI is AI
focused on the creation of agents that can successfully pass tests.  This approach offers a number of
benefits, including a well-defined domain, a built-in measure for quantifying the efficacy
of the agent in the form of a test score, and a rich environment for deploying various
forms of AI, including machine learning, natural language processing, computer vision,
et cetera.  Although, in this work, our attention we'll be centered around natural language 
processing.

As part of our commitment to this psychometric approach, we set our sights on one
particular test
in the fraud-detection domain, namely, the 
Certified Fraud Examiners (CFE) exam, administered by the Association of Fraud Examiners 
(ACFE).  As will be discussed in more detail herein, the ACFE is a governing body overseeing
the fraud examiners profession, administering the CFE exam as part of a credentialling
process for its members.  The CFE exam is a multiple-choice exam whose questions
are based on the material of the Fraud Examiners Manual (FEM).  Programmatic processing of both the FEM and of a training set of CFE exam 
questions generate the basis of the agent's knowledge and decisions for answering new
questions on the test.

The approaches employed in the work presented herein range over a variety of techniques, from 
extremely shallow text-processing techniques to deep, cognitive, semantic-representation
techniques.  Version 1 of the agent focuses on shallow text processing techniques that leverage features of the 
exam and the high-level structure of the document.  Analysis of these shallow algorithms 
on a training set is then used to apply these algorithms optimally on a test set.  As we'll discuss, even these relatively simplistic techniques generate surprisingly decent scores, although not ones at the level of passing.  Version 2 picks up where version 1 left off by employing more sophisticated information
retrieval-based approaches to the question-answer task, wherein the agent breaks up 
the document along much more granular, hierarchical lines reflecting the structure of 
the manual's sections, subsections, sub-subsections, and so on.  Version 3 refines the techniques of Version 2 by incorporating machine learning in order to zero in on the paragraphs within the FEM relevant to each question.
Finally, version 4 features an agent with a deep, semantic representation of the problem
domain, whose knowledge-base consists of assertions expressed in the \textit{deontic
cognitive event calculus} $\mathcal{DCEC}^\ast$, and which serve as a foundation for the rigorous science of
fraud detection.

It is hoped that by the end of this exploration, the reader will have a solid understanding
of the various techniques discussed herein, an appreciation of the benefits of using psychometric AI
as the backdrop for intelligent-agent development, and some insights into the relative potential of each of these approaches.