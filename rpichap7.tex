%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%                                                                 %
%                            CHAPTER SEVEN  - Conclusion and Future Work            %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
 

\chapter{Conclusion and Future Work}

This chapter summarizes the work we’ve covered in this dissertation and offers areas for further investigation.

\section{Summary of Work}

The research underpinning this dissertation began with developing a battery of multiple choice questions from the CFE exam materials and the preparation of the CFE Manual text for test processing by an automated agent. This laid the groundwork for the development of the agents discussed in detail above for which a comparative analysis of accuracy, complexity, and provision for reasoning justification could be accomplished.  Version 1 of the CFE agent uses only primitive rule-based algorithms, but performs effectively, showing improved performance over random guessing at the 99\% level of statistical significance.  Unfortunately, justifications for the agent’s answers are minimal, offering little more explanation than the choice of a particular algorithm based on relative performance in the training set.  

In Version 2 of the agent, more sophisticated algorithms are brought to bear on the problem using information retrieval for which we see marked improvement in accuracy (a jump from roughly 49\% accuracy to 59.5\%, and in particular, a 70\% accuracy rate for Concept Match V3 on definition questions) and a more transparent justification for the agent’s answers. However, the justifications in the agent's answers are still not \emph{completely} transparent as the coefficients upon which the cosine similarity computations are based are derived from term counts within the documents of the document collection. And so, justifications are thus limited to showing how these coefficients determined at the aggregate level are applied at the level of each individual question.

Version 3 of the agent uses machine learning to isolate the passages (paragraphs) from among the documents in the document collection relevant to each definition question. This technique, with its added complexity, provides 93\% probability that the correct passage is within the selection of top seven passages as ranked by the logistic regression
algorithm in the test set. Although the relatively simplistic answer extraction algorithms that utilize the results of the passage selection algorithm yield roughly 69\% accuracy on the definition questions in the test set, we believe further work to refine these answer extraction algorithms will result in significant accuracy gains, surpassing those of Version 2 at a statistically significant level. However, as we have observed with Version 2, this approach offers only limited transparency into the reasoning by the agent, limited to the application of opaquely determined coefficients at the aggregate level to each individual problem.

Finally, in Version 4 of the agent, we demonstrated how an agent using formal semantic reasoning as the basis for a rigorous, mechanistic approach to fraud detection should behave, and looked at the complex issues associated with building such an agent.  This approach offers the benefit of completely transparent reasoning based on natural deduction using the $\mathcal{DCEC}^\ast$.  However, our work, here, highlights an two important issues with this approach -- the problem of translating assertions expressed in natural language into a formal language, (in our case, again, the language of choice was the $\mathcal{DCEC}^\ast$), and that of a natural deduction theorem prover.  This problem exists for both translating assertions in the information source (the CFE Manual, in our example), and for translating declarations germane to the problem at hand. In the example we covered in Chapter 6, these were the assertions associated with Blue and his interactions with Dr. White and Dr. Black.

\section{Future Work}

Certainly, as alluded to in the above paragraphs, the incorporation of machine learning into passage selection offers considerable promise for refining the algorithms of the CFE agent. So, continuing along this path, further refinement of the answer extraction algorithms would also likely deliver improved overall accuracy, as discussed above. Specifically, perhaps incorporation of machine learning in the answer extraction algorithm as well as the passage selection algorithm may prove beneficial. This is a tack that will be pursued in future work.  

Another avenue for investigation is the approach for algorithm selection for a given question.  As discussed, the current approach in Version 1, 2, and 3 is to select that algorithm with the highest accuracy for the given question's type.  However, there are other possibilities for selecting an algorithm/answer -- one suggestion is to use a voting mechanism in which the most accurate algorithms for the question type each weigh in with a vote for a candidate answer.  The answer receiving the highest number of votes weighted by the accuracy of its constituent algorithms is the one selected.

Now, consider the following problem from the CFE test set:

\blockquote{True or False: Green, an agent for the White Corporation, acting within the scope of his duties and for the benefit of White, committed an act of fraud. According to the Sentencing Guidelines effective in 1991, White cannot be held criminally liable for Green's actions. \cite{acfe_study_package_2011}}

This is a true/false question, a type that is not specifically targeted in any of the first three versions of the CFE agent. The reason for that is obvious – this is a tough problem for the CFE Agent using the algorithms of Versions 1, 2, and 3 where the algorithms are looking for the juxtaposition of key words of the question stem and those of the various answer options within the CFE Manual. In a true/false problem, however, answer options are of no help, leaving the agent with only the question stem from which it must discern whether the statement is valid.  Using proximity of key words will likely not work here as it is likely that such questions with keywords richly represented in a particular section are as likely to be invalid as valid. 

An algorithm that is based on a semantic understanding of the problem would certainly appear useful, here. But for that, we'd need the tools for translating natural language assertions to ones expressed in a formal language, where in our case, we'd recommend the $\mathcal{DCEC}^\ast$ due to its built-in support for modeling the cognitive states and interactions typical of agents in financial fraud scenarios. There are two possible approaches for tackling this task. The first approach to the translation problem is a computational semantics approach based on Blackburn and Bos \cite{blackburn_2005_representation_ch1, blackburn_2005_representation_ch2, blackburn_2005_representation_ch3, blackburn_2005_representation_ch4, blackburn_2005_representation_ch5, blackburn_2005_representation_ch6} using Prolog \cite{
blackburn_2006_prolog_ch7,
blackburn_2006_prolog_ch8,
blackburn_2006_prolog_ch9,
blackburn_2006_prolog_ch10,
blackburn_2006_prolog_ch11,
blackburn_2006_prolog_ch12}, wherein the authors explain an approach to the representation of natural language assertions in first-order logic ($\mathcal{FOL}$) \cite{blackburn_2005_representation_ch1} using the lambda calculus \cite{blackburn_2005_representation_ch2} and inference \cite{blackburn_2005_representation_ch4, blackburn_2005_representation_ch5} from these $\mathcal{FOL}$ assertions. In the approach we propose here, however, the target representation language would be the $\mathcal{DCEC}^\ast$, not $\mathcal{FOL}$.  A second approach would involve parsing the sentences first, using a probabilistic parser \cite{martin_2000_speech_ch14}, such as OpenNLP \cite{opennlp} or the Stanford Parser \cite{stanford_parser}, and then translating the parse structures into assertions expressed in the $\mathcal{DCEC}^\ast$.  The idea here is that both the natural language utterances and the parse structures serve as inputs to the computational semantic model that produces the output assertions in the $\mathcal{DCEC}^\ast$ from which inferences can be drawn using a theorem prover.  Having parse structures as inputs may be helpful in better capturing the semantics of the utterance in the semantic model. 

As a final thought, we believe that in order to build a QA system that provides both accurate answers and reasoning justification, a hybrid approach may be best; one that combines statistical approaches, like those discussed for Versions 1, 2, and 3 of the agent, with logicist approaches, like the one discussed for Version 4. For example, for definition questions, we might leverage machine learning to arrive at a candidate answer and then use formal logic to to engineer the justification for that answer.  Such an approach would side-step the halting problem that makes provability in $\mathcal{FOL}$ semi-decidable \cite{cook1971complexity}.  This is a direction for future work.